{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a00fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd4b64c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,3,4,6,8,6])\n",
    "y = np.array([19,10,5,25,17,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6624f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x,y):\n",
    "    weight = 0.1\n",
    "    bias = 0.1\n",
    "    learning_rate = 0.05\n",
    "    n = len(x)\n",
    "    iteration = 100\n",
    "    \n",
    "    #Forward propagation\n",
    "    for i in range(iteration):\n",
    "        ypred = weight*x+bias\n",
    "        mse = mean_squared_error(y, ypred)\n",
    "        \n",
    "        #Backward propagation\n",
    "        dw = -(2/n)*sum(x*(y - ypred))\n",
    "        db = -(2/n)*sum(y - ypred)\n",
    "        \n",
    "        #Update the weights and bias\n",
    "        weight = weight - (learning_rate*dw)\n",
    "        bias  = bias - (learning_rate*db)\n",
    "        \n",
    "        print(f\"{i} MSE: {mse}, Weight: {weight}, Bias: {bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5fadb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MSE: 281.34000000000003, Weight: 7.7, Bias: 1.6433333333333335\n",
      "1 MSE: 749.8781, Weight: -5.940222222222224, Bias: -0.5143333333333335\n",
      "2 MSE: 2238.5025787283957, Weight: 18.255066666666668, Bias: 3.9092037037037044\n",
      "3 MSE: 6963.5357520734315, Weight: -24.941241728395074, Bias: -3.4007477777777786\n",
      "4 MSE: 21956.83131533721, Weight: 51.903793234567914, Bias: 10.178573139917699\n",
      "5 MSE: 69528.75090922772, Weight: -85.06978263072706, Bias: -13.461054350205767\n",
      "6 MSE: 220464.64009177047, Weight: 158.81712250233204, Bias: 29.184282979154116\n",
      "7 MSE: 699349.1602730671, Weight: -275.6917736442363, Bias: -46.248802486516254\n",
      "8 MSE: 2218734.7379991836, Weight: 498.17545635557605, Bias: 88.6322387961123\n",
      "9 MSE: 7039376.654457554, Weight: -880.3433205759984, Bias: -151.11286471610106\n",
      "10 MSE: 22334100.721868377, Weight: 1575.0196485133774, Bias: 276.425304690975\n",
      "11 MSE: 70860536.01631801, Weight: -2798.615211328529, Bias: -484.62639508436524\n",
      "12 MSE: 224823096.0686079, Weight: 4991.721510297869, Bias: 871.4566763773851\n",
      "13 MSE: 713308796.7445096, Weight: -8884.689683149158, Bias: -1543.5590293993587\n",
      "14 MSE: 2263154936.093292, Weight: 15832.216675073269, Bias: 2758.5853923435166\n",
      "15 MSE: 7180439210.565944, Weight: -28194.191530718203, Bias: -4904.040928591694\n",
      "16 MSE: 22781784413.652065, Weight: 50226.59470223039, Bias: 8745.2525452693\n",
      "17 MSE: 72281052413.31406, Weight: -89458.41218158399, Bias: -15566.750236965145\n",
      "18 MSE: 229330172253.14224, Weight: 159351.70081927656, Bias: 27738.7838048039\n",
      "19 MSE: 727608773918.7241, Weight: -283834.74050167855, Bias: -49397.62162467223\n",
      "20 MSE: 2308525401344.9, Weight: 505579.1989443671, Bias: 87999.95277191163\n",
      "21 MSE: 7324388764766.634, Weight: -900543.3661656495, Bias: -156735.40201265085\n",
      "22 MSE: 23238501402997.926, Weight: 1604074.8267541742, Bias: 279193.30906591733\n",
      "23 MSE: 73730104286201.9, Weight: -2857209.4997128583, Bias: -497292.67432595574\n",
      "24 MSE: 233927660987578.0, Weight: 5089333.9808639735, Bias: 885802.6263059736\n",
      "25 MSE: 742195485886188.8, Weight: -9065234.409744877, Bias: -1577798.5607278114\n",
      "26 MSE: 2354805485355332.5, Weight: 16147212.408239268, Bias: 2810425.6198925786\n",
      "27 MSE: 7471224198081483.0, Weight: -28761785.133289963, Bias: -5005981.132608337\n",
      "28 MSE: 2.3704374465382196e+16, Weight: 51231167.171810165, Bias: 8916784.976187812\n",
      "29 MSE: 7.520820603126238e+16, Weight: -91254142.59763159, Bias: -15882769.934942381\n",
      "30 MSE: 2.386173177740346e+17, Weight: 162544009.63561344, Bias: 28290775.204113267\n",
      "31 MSE: 7.570746245164609e+17, Weight: -289527170.2257957, Bias: -50392171.87958432\n",
      "32 MSE: 2.4020133678206566e+18, Weight: 515712544.17765874, Bias: 89759726.34707877\n",
      "33 MSE: 7.621003309778329e+18, Weight: -918599189.4806569, Bias: -159882098.63720316\n",
      "34 MSE: 2.4179587102110052e+19, Weight: 1636230276.0644782, Bias: 284785734.58415705\n",
      "35 MSE: 7.671593997057745e+19, Weight: -2914491470.865553, Bias: -507266966.1043486\n",
      "36 MSE: 2.434009902946462e+20, Weight: 5191360092.570136, Bias: 903555751.8433442\n",
      "37 MSE: 7.722520521698112e+20, Weight: -9246971500.312794, Bias: -1609434531.6070533\n",
      "38 MSE: 2.4501676486958923e+21, Weight: 16470921006.531704, Bias: 2866762289.96629\n",
      "39 MSE: 7.773785113096567e+21, Weight: -29338388105.171497, Bias: -5106343740.478468\n",
      "40 MSE: 2.466432654792694e+22, Weight: 52258220198.9315, Bias: 9095538417.582745\n",
      "41 MSE: 7.8253900154497e+22, Weight: -93083558925.13881, Bias: -16201184848.743565\n",
      "42 MSE: 2.482805633265783e+23, Weight: 165802603110.06628, Bias: 28857927802.795574\n",
      "43 MSE: 7.877337487851796e+23, Weight: -295331458253.8339, Bias: -51402413093.91492\n",
      "44 MSE: 2.4992873008707473e+24, Weight: 526051271816.5948, Bias: 91559175402.19907\n",
      "45 MSE: 7.929629804393763e+24, Weight: -937014777267.9875, Bias: -163087335650.8317\n",
      "46 MSE: 2.5158783791212372e+25, Weight: 1669032544667.217, Bias: 290494960640.91223\n",
      "47 MSE: 7.982269254262638e+25, Weight: -2972919640892.1113, Bias: -517436389599.61365\n",
      "48 MSE: 2.5325795943205325e+26, Weight: 5295433704670.992, Bias: 921669748444.933\n",
      "49 MSE: 8.035258141841825e+26, Weight: -9432349847207.07, Bias: -1641699621911.0898\n",
      "50 MSE: 2.549391677593359e+27, Weight: 16801121230485.113, Bias: 2924233602311.585\n",
      "51 MSE: 8.088598786811977e+27, Weight: -29926548439562.176, Bias: -5208712998811.026\n",
      "52 MSE: 2.5663153649178835e+28, Weight: 53305865080042.09, Bias: 9277880906200.691\n",
      "53 MSE: 8.142293524252538e+28, Weight: -94949648392290.62, Bias: -16525977555104.09\n",
      "54 MSE: 2.5833513971579322e+29, Weight: 169126525125950.6, Bias: 29436456116810.215\n",
      "55 MSE: 8.196344704743973e+29, Weight: -301252105568619.5, Bias: -52432901220312.81\n",
      "56 MSE: 2.6005005200954286e+30, Weight: 536597266702807.0, Bias: 93394704833742.5\n",
      "57 MSE: 8.25075469447064e+30, Weight: -955799548983844.0, Bias: -166356823444273.4\n",
      "58 MSE: 2.617763484463032e+31, Weight: 1702492417546537.0, Bias: 296318648425949.4\n",
      "59 MSE: 8.30552587532442e+31, Weight: -3032519145761215.0, Bias: -527809677938361.25\n",
      "60 MSE: 2.6351410459770137e+32, Weight: 5401593730831976.0, Bias: 940146891210710.0\n",
      "61 MSE: 8.360660645008944e+32, Weight: -9621444558312680.0, Bias: -1674611538965282.0\n",
      "62 MSE: 2.6526339653703316e+33, Weight: 1.7137941133982028e+16, Bias: 2982857075477165.0\n",
      "63 MSE: 8.416161417144572e+33, Weight: -3.052649989632546e+16, Bias: -5313134494595496.0\n",
      "64 MSE: 2.670243008425938e+34, Weight: 5.437451258789786e+16, Bias: 9463878906482604.0\n",
      "65 MSE: 8.472030621374093e+34, Weight: -9.685314822245155e+16, Bias: -1.685728152518466e+16\n",
      "66 MSE: 2.687968946010294e+35, Weight: 1.7251708335658717e+17, Bias: 3.002658246447786e+16\n",
      "67 MSE: 8.528270703469003e+35, Weight: -3.072914468562879e+17, Bias: -5.348404801504395e+16\n",
      "68 MSE: 2.7058125541071314e+36, Weight: 5.4735468206271e+17, Bias: 9.526703198606142e+16\n",
      "69 MSE: 8.58488412543666e+36, Weight: -9.749609077667692e+17, Bias: -1.6969185617514272e+17\n",
      "70 MSE: 2.7237746138514057e+37, Weight: 1.7366230760852408e+18, Bias: 3.0225908640019725e+17\n",
      "71 MSE: 8.641873365628e+37, Weight: -3.0933134696650015e+18, Bias: -5.383909244129348e+17\n",
      "72 MSE: 2.741855911563499e+38, Weight: 5.509881996489872e+18, Bias: 9.58994453872026e+17\n",
      "73 MSE: 8.699240918846068e+38, Weight: -9.814330139173065e+18, Bias: -1.708183256543784e+18\n",
      "74 MSE: 2.76005723878365e+39, Weight: 1.7481513422981313e+19, Bias: 3.042655800724691e+18\n",
      "75 MSE: 8.756989296455214e+39, Weight: -3.1138478859406414e+19, Bias: -5.419649376739057e+18\n",
      "76 MSE: 2.778379392306588e+40, Weight: 5.546458377013581e+19, Bias: 9.653605695324512e+18\n",
      "77 MSE: 8.815121026491034e+40, Weight: -9.879480840038231e+19, Bias: -1.7195227300271317e+19\n",
      "78 MSE: 2.796823174216432e+41, Weight: 1.7597561368744323e+20, Bias: 3.0628539349934227e+19\n",
      "79 MSE: 8.873638653771051e+41, Weight: -3.134518616319561e+20, Bias: -5.455626763919937e+19\n",
      "80 MSE: 2.815389391921789e+42, Weight: 5.583277563392851e+20, Bias: 9.717689455296676e+19\n",
      "81 MSE: 8.932544740006105e+42, Weight: -9.945064032348361e+20, Bias: -1.73093747860663e+20\n",
      "82 MSE: 2.8340788581911116e+43, Weight: 1.7714379678341973e+21, Bias: 3.083186151016601e+20\n",
      "83 MSE: 8.991841863912504e+43, Weight: -3.1553265656989095e+21, Bias: -5.491842980644647e+20\n",
      "84 MSE: 2.8528923911882645e+44, Weight: 5.620341167451564e+21, Bias: 9.782198624014729e+20\n",
      "85 MSE: 9.051532621324905e+44, Weight: -1.001108258712168e+22, Bias: -1.7424280019827373e+21\n",
      "86 MSE: 2.871830814508359e+45, Weight: 1.78319734656988e+22, Bias: 3.103653338872321e+21\n",
      "87 MSE: 9.111619625309975e+45, Weight: -3.176272644982839e+22, Bias: -5.528299612341018e+21\n",
      "88 MSE: 2.8908949572137913e+46, Weight: 5.657650811713408e+22, Bias: 9.847136025479668e+21\n",
      "89 MSE: 9.17210550628074e+46, Weight: -1.0077539394435177e+23, Bias: -1.753994803173087e+22\n",
      "90 MSE: 2.9100856538705396e+47, Weight: 1.795034787868724e+23, Bias: 3.1242563945473046e+22\n",
      "91 MSE: 9.232992912111755e+47, Weight: -3.1973577711223716e+23, Bias: -5.56499825496147e+22\n",
      "92 MSE: 2.9294037445847056e+48, Weight: 5.6952081294729e+23, Bias: 9.912504502439077e+22\n",
      "93 MSE: 9.294284508255051e+48, Weight: -1.0144437363551087e+24, Bias: -1.765638388534503e+23\n",
      "94 MSE: 2.9488500750392884e+49, Weight: 1.806950809935295e+24, Bias: 3.144996219976121e+23\n",
      "95 MSE: 9.355982977856773e+49, Weight: -3.218582867155554e+24, Bias: -5.6019405150528674e+23\n",
      "96 MSE: 2.9684254965312018e+50, Weight: 5.733014764866909e+24, Bias: 9.978306916511669e+23\n",
      "97 MSE: 9.418091021874673e+50, Weight: -1.021177942304429e+25, Bias: -1.777359267785174e+24\n",
      "98 MSE: 2.9881308660085456e+51, Weight: 1.8189459344141705e+25, Bias: 3.1658737230806785e+24\n",
      "99 MSE: 9.480611359196312e+51, Weight: -3.2399488622478547e+25, Bias: -5.639128009826852e+24\n"
     ]
    }
   ],
   "source": [
    "gradient_descent(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeed01ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
